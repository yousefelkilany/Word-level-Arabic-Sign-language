{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5612889,"sourceType":"datasetVersion","datasetId":3211537}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\ngdrive_kaggle_wl_ar_sl = user_secrets.get_secret(\"gdrive_kaggle_wl_ar_sl\")\n\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\ndef upload_to_gdrive(file_name, file_content):\n    file_metadata = {\n        'title': file_name,\n        'parents': [{'id': gdrive_kaggle_wl_ar_sl}]\n    }\n    file = drive.CreateFile(file_metadata)\n    file.SetContentString(file_content)\n    file.Upload() # Files.insert()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T14:00:43.469508Z","iopub.execute_input":"2025-08-03T14:00:43.469825Z","iopub.status.idle":"2025-08-03T14:00:44.472357Z","shell.execute_reply.started":"2025-08-03T14:00:43.469795Z","shell.execute_reply":"2025-08-03T14:00:44.471479Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!export TF_CPP_MIN_LOG_LEVEL=2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T18:06:55.281014Z","iopub.execute_input":"2025-08-04T18:06:55.281555Z","iopub.status.idle":"2025-08-04T18:06:55.689972Z","shell.execute_reply.started":"2025-08-04T18:06:55.281532Z","shell.execute_reply":"2025-08-04T18:06:55.689090Z"}},"outputs":[],"execution_count":220},{"cell_type":"code","source":"!pip install opencv-python mediapipe sklearn matplotlib\n!wget https://github.com/issamjebnouni/Arabic-Word-level-Sign-Language-Recognition/raw/refs/heads/main/KARSL-502_Labels.xlsx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:33:08.878547Z","iopub.execute_input":"2025-08-04T15:33:08.878838Z","iopub.status.idle":"2025-08-04T15:33:49.074687Z","shell.execute_reply.started":"2025-08-04T15:33:08.878812Z","shell.execute_reply":"2025-08-04T15:33:49.073979Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\nRequirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.7.2)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\nCollecting protobuf<5,>=4.25.3 (from mediapipe)\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting sounddevice>=0.4.4 (from mediapipe)\n  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2.4.1)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\nDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\nInstalling collected packages: protobuf, sounddevice, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.21 protobuf-4.25.8 sounddevice-0.5.2\n--2025-08-04 15:33:48--  https://github.com/issamjebnouni/Arabic-Word-level-Sign-Language-Recognition/raw/refs/heads/main/KARSL-502_Labels.xlsx\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/issamjebnouni/Arabic-Word-level-Sign-Language-Recognition/refs/heads/main/KARSL-502_Labels.xlsx [following]\n--2025-08-04 15:33:48--  https://raw.githubusercontent.com/issamjebnouni/Arabic-Word-level-Sign-Language-Recognition/refs/heads/main/KARSL-502_Labels.xlsx\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 26778 (26K) [application/octet-stream]\nSaving to: ‘KARSL-502_Labels.xlsx’\n\nKARSL-502_Labels.xl 100%[===================>]  26.15K  --.-KB/s    in 0.002s  \n\n2025-08-04 15:33:48 (10.7 MB/s) - ‘KARSL-502_Labels.xlsx’ saved [26778/26778]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport mediapipe as mp\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict\nfrom concurrent.futures import ThreadPoolExecutor\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # '2' suppresses warnings and info messages\nos_join = os.path.join\n\nDATA_DIR = \"/kaggle/input/karsl-502\"\nKPS_DIR = \"/kaggle/working/karsl-kps\"\n\nmp_hands = mp.solutions.hands\nmp_pose = mp.solutions.pose\nmp_face = mp.solutions.face_mesh\n\nmp_face_nose_idx = sorted(mp.solutions.face_mesh_connections.FACEMESH_NOSE)[0][0]\nmp_hand_wrist_idx = mp.solutions.hands.HandLandmark.WRIST\nmp_pose_nose_idx = mp.solutions.pose.PoseLandmark.NOSE\n\npose_kps_idx = tuple(\n    (\n        mp.solutions.pose.PoseLandmark.LEFT_SHOULDER,\n        mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER,\n        mp.solutions.pose.PoseLandmark.LEFT_ELBOW,\n        mp.solutions.pose.PoseLandmark.RIGHT_ELBOW,\n        mp.solutions.pose.PoseLandmark.LEFT_WRIST,\n        mp.solutions.pose.PoseLandmark.RIGHT_WRIST,\n    )\n)\nface_kps_idx = tuple(\n    sorted(\n        set(\n            point\n            for edge in [\n                *mp.solutions.face_mesh_connections.FACEMESH_CONTOURS,\n                *mp.solutions.face_mesh_connections.FACEMESH_IRISES,\n            ]\n            for point in edge\n        )\n    )\n)\nhand_kps_idx = tuple(range(len(mp.solutions.hands.HandLandmark)))\n\nPOSE_NUM = len(pose_kps_idx)\nFACE_NUM = len(face_kps_idx)\nHAND_NUM = len(hand_kps_idx)\n\nKP2SLICE = {\n    \"pose\": slice(0, POSE_NUM),\n    \"face\": slice(POSE_NUM, POSE_NUM + FACE_NUM),\n    \"rh\": slice(POSE_NUM + FACE_NUM, POSE_NUM + FACE_NUM + HAND_NUM),\n    \"lh\": slice(POSE_NUM + FACE_NUM + HAND_NUM, POSE_NUM + FACE_NUM + HAND_NUM * 2),\n}\nPOSE_KPS2IDX = {kps: idx for idx, kps in enumerate(pose_kps_idx)}\nFACE_KPS2IDX = {kps: idx for idx, kps in enumerate(face_kps_idx)}\nHAND_KPS2IDX = {kps: idx for idx, kps in enumerate(hand_kps_idx)}\nKPS2IDX = {\"pose\": POSE_KPS2IDX, \"face\": FACE_KPS2IDX, \"hand\": HAND_KPS2IDX}\n\n\n# usage: use it to draw mediapipe connections with the kps loaded from `.npy`arrays\nfor u, v in list(mp.solutions.face_mesh_connections.FACEMESH_IRISES)[:3]:\n    print(face_kps_idx[FACE_KPS2IDX[u]], face_kps_idx[FACE_KPS2IDX[v]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:41:35.298905Z","iopub.execute_input":"2025-08-04T17:41:35.299481Z","iopub.status.idle":"2025-08-04T17:41:35.309261Z","shell.execute_reply.started":"2025-08-04T17:41:35.299458Z","shell.execute_reply":"2025-08-04T17:41:35.308461Z"}},"outputs":[{"name":"stdout","text":"475 476\n477 474\n469 470\n","output_type":"stream"}],"execution_count":181},{"cell_type":"code","source":"def get_karsl_words_min_frames_cnt():\n    in_dir = \"/kaggle/input/karsl-502\"\n    words_frames = defaultdict(lambda: (0, None))\n    for signer in tqdm([\"01\", \"02\", \"03\"], desc=\"signer\"):\n        signer_dir = os_join(in_dir, signer, signer)\n\n        for split in tqdm([\"train\", \"test\"], desc=\"split\", leave=False):\n            split_dir = os_join(signer_dir, split)\n\n            for word in tqdm(range(1, 503), desc=\"words\", leave=False):\n                frames = (999, None)\n                word_dir = os_join(split_dir, f\"{word:04}\")\n\n                for rep in os.listdir(word_dir):\n                    frames_dir = os_join(word_dir, rep)\n                    frames_cnt = len(os.listdir(frames_dir))\n                    if frames_cnt < frames[0]:\n                        frames = (frames_cnt, frames_dir)\n\n                if frames[0] > words_frames[word][0]:\n                    words_frames[word] = frames\n    return words_frames\n\n\n# words_frames = get_karsl_words_min_frames_cnt()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:41:35.352292Z","iopub.execute_input":"2025-08-04T15:41:35.353043Z","iopub.status.idle":"2025-08-04T15:41:35.358410Z","shell.execute_reply.started":"2025-08-04T15:41:35.353017Z","shell.execute_reply":"2025-08-04T15:41:35.357762Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# !tar -cf sample.tar.gz '/kaggle/input/karsl-502/03/03/test/0102/03_03_0102_(22_12_16_10_40_19)_c'\n# sorted(words_frames.values())","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bad_samples = [\n    # this sample has >260 frames, and after inspection it has many unrelated frames, so just drop it\n    'karsl-502/02/02/train/0443/03_02_0443_(15_11_17_15_52_07)_c',\n]\n\nPAD_TKN = -1\nSEQ_LEN = 80","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:47:22.938853Z","iopub.execute_input":"2025-08-04T15:47:22.939393Z","iopub.status.idle":"2025-08-04T15:47:22.943039Z","shell.execute_reply.started":"2025-08-04T15:47:22.939369Z","shell.execute_reply":"2025-08-04T15:47:22.942283Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"image_path = '/kaggle/input/karsl-502/01/01/train/0001/01_01_0001_(10_11_16_16_21_34)_c/01_01_0001_(10_11_16_16_21_34)_c_0019.jpg'\n# np_xyz = np.dtype((float, 3))\n# frame = cv2.imread(image_path)\n\n# hands_model = mp_hands.Hands()\n# pose_model = mp_pose.Pose()\n# face_model = mp_face.FaceMesh(refine_landmarks=True)\n\n# pose_res = pose_model.process(frame)\n# print(dir(pose_res.pose_landmarks))\n# print(pose_res.pose_landmarks)\n# face_res = face_model.process(frame)\n# print(dir(face_res.multi_face_landmarks))\n# print(len(face_res.multi_face_landmarks))\n# print(face_res.multi_face_landmarks)\n# hands_res = hands_model.process(frame)\n# print(dir(hands_res.multi_hand_landmarks))\n# print(hands_res.multi_hand_landmarks)\n\n# hands_model.reset()\n# pose_model.reset()\n# face_model.reset()\n\n\n# print(results.right_hand)\n# all_kps = np.zeros((184, 3))  # (pose=6 + face=136 + rh+lh=42), xyz=3\n# pose_kps = all_kps[KP2SLICE[\"pose\"]]\n# lms = results.pose_landmarks.landmark\n# pose_kps[:] = np.fromiter((get_xyz(lms[idx]) for idx in pose_kps_idx), dtype=np.dtype((float, 3)))\n# pose_kps[:] = np.array([get_xyz(lms[idx]) for idx in pose_kps_idx])\n# print(pose_kps)\n# pose_kps -= pose_kps[mp_pose_nose_idx]\n# face_kps = all_kps[KP2SLICE[\"face\"]]\n# lms = results.face_landmarks.landmark\n# face_kps[:] = np.fromiter(((lms[idx].x, lms[idx].y, lms[idx].z) for idx in face_kps_idx), dtype=np_xyz)\n\n# print(all_kps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:57:34.508303Z","iopub.execute_input":"2025-08-04T17:57:34.508954Z","iopub.status.idle":"2025-08-04T17:57:34.512963Z","shell.execute_reply.started":"2025-08-04T17:57:34.508929Z","shell.execute_reply":"2025-08-04T17:57:34.512269Z"},"scrolled":true},"outputs":[],"execution_count":202},{"cell_type":"code","source":"def extract_frame_keypoints(frame, pose_model, face_model, hands_model):\n    # TODO: normalize(?) keypoints after adjustment\n\n    def get_xyz(lm):\n        return (lm.x, lm.y, lm.z)\n\n    # define numpy views, pose -> face -> rh -> lh\n    all_kps = np.zeros((184, 3))  # (pose=6 + face=136 + rh+lh=42), xyz=3\n    pose_kps = all_kps[KP2SLICE[\"pose\"]]\n    face_kps = all_kps[KP2SLICE[\"face\"]]\n    rh_kps = all_kps[KP2SLICE[\"rh\"]]\n    lh_kps = all_kps[KP2SLICE[\"lh\"]]\n    np_xyz = np.dtype((float, 3))\n\n    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    \n    def get_pose():\n        nonlocal pose_kps\n        results = pose_model.process(image_rgb)\n        if results.pose_landmarks is None:\n            return\n\n        lms = results.pose_landmarks.landmark\n        pose_kps[:] = np.fromiter(((lms[idx].x, lms[idx].y, lms[idx].z) for idx in pose_kps_idx), dtype=np_xyz)\n        # pose_kps -= pose_kps[mp_pose_nose_idx]\n\n    def get_face():\n        nonlocal face_kps\n        results = face_model.process(image_rgb)\n        if results.multi_face_landmarks is None:\n            return\n\n        lms = results.multi_face_landmarks[0].landmark\n        face_kps[:] = np.fromiter(((lms[idx].x, lms[idx].y, lms[idx].z) for idx in face_kps_idx), dtype=np_xyz)\n        # face_kps -= face_kps[mp_face_nose_idx]\n\n    def get_hands():\n        nonlocal rh_kps, lh_kps\n        results = hands_model.process(image_rgb)\n        if results.multi_hand_landmarks is None:\n            return\n\n        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n            if results.multi_handedness[i].classification[0].index == 0:\n                lms = hand_landmarks.landmark\n                rh_kps[:] = np.fromiter(((lm.x, lm.y, lm.z) for lm in lms), dtype=np_xyz)\n                # rh_kps -= rh_kps[mp_hand_wrist_idx]\n            else:\n                lms = hand_landmarks.landmark\n                lh_kps[:] = np.fromiter(((lm.x, lm.y, lm.z) for lm in lms), dtype=np_xyz)\n                # lh_kps -= lh_kps[mp_hand_wrist_idx]\n\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        executor.submit(get_pose)\n        executor.submit(get_face)\n        executor.submit(get_hands)\n    \n    return all_kps\n\n\ndef store_keypoint_arrays(data_dir, out_dir, signer, split, selected_words=None):\n    \"\"\"This function generates numpy arrays of keypoints for each video in the specified folder location.\n    Args:\n      signer(int): the signer of interest. Could be 01 or 02 or 03\n      split(str): can be 'train', 'test' or 'val'\n    \"\"\"\n\n    hands_model = mp_hands.Hands()\n    pose_model = mp_pose.Pose()\n    face_model = mp_face.FaceMesh(refine_landmarks=True)\n\n    selected_words = selected_words or [f\"{w:04}\" for w in range(1, 503)]\n    # out_dir = os_join(out_dir, \"karsl-502\", signer, split)\n    # os.makedirs(out_dir, exist_ok=True)\n\n    split_dir = os_join(data_dir, signer, signer, split)\n    words_bar = tqdm(selected_words, desc=split_dir)\n    for word in words_bar:\n        word_kps_dir = os_join(out_dir, \"all_kps\", f\"{signer}-{split}\", word)\n        words_bar.set_description(f\"Current iteration: {word_kps_dir}\")\n        os.makedirs(word_kps_dir, exist_ok=True)\n\n        word_dir = os_join(split_dir, word)\n        videos_bar = tqdm(os.listdir(word_dir), leave=False)\n        all_kps = []\n        for video in videos_bar:\n            video_dir = os_join(word_dir, video)\n            videos_bar.set_description(f\"Current video: {video_dir}\")\n            video_frames = sorted(os.listdir(video_dir))\n            video_kps_dir = os_join(word_kps_dir, video)\n\n            video_kps = []\n            for frame in video_frames:\n                frame = cv2.imread(os_join(video_dir, frame))\n                video_kps.append(\n                    extract_frame_keypoints(frame, pose_model, face_model, hands_model)\n                )\n\n            pose_model.reset()\n            face_model.reset()\n            hands_model.reset()\n\n            all_kps.append(video_kps.copy())\n            # np.save(video_kps_dir, video_kps)\n        np.savez(word_kps_dir, keypoints=np.concatenate(all_kps, axis=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T18:07:02.709512Z","iopub.execute_input":"2025-08-04T18:07:02.709840Z","iopub.status.idle":"2025-08-04T18:07:02.725016Z","shell.execute_reply.started":"2025-08-04T18:07:02.709794Z","shell.execute_reply":"2025-08-04T18:07:02.724348Z"}},"outputs":[],"execution_count":221},{"cell_type":"code","source":"!export TF_CPP_MIN_LOG_LEVEL=3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T18:07:24.808188Z","iopub.execute_input":"2025-08-04T18:07:24.808706Z","iopub.status.idle":"2025-08-04T18:07:25.202971Z","shell.execute_reply.started":"2025-08-04T18:07:24.808670Z","shell.execute_reply":"2025-08-04T18:07:25.202036Z"}},"outputs":[],"execution_count":223},{"cell_type":"code","source":"def extract_keypoints_from_frames(data_dir, kps_dir, signers=None, splits=None):\n    if signers is None:\n        signers = [\"01\", \"02\", \"03\"]\n    if splits is None:\n        splits = [\"train\", \"test\"]\n    for signer in signers:\n        for split in splits:\n            # selected_words = [f'{3:04}'] # [f\"{w:04}\" for w in range(1, 503)][2::999999]\n            selected_words = [f\"{w:04}\" for w in range(4, 503)]\n            store_keypoint_arrays(data_dir, kps_dir, signer, split, selected_words)\n\nextract_keypoints_from_frames(DATA_DIR, KPS_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T18:07:25.227136Z","iopub.execute_input":"2025-08-04T18:07:25.227365Z","iopub.status.idle":"2025-08-04T18:07:27.441208Z","shell.execute_reply.started":"2025-08-04T18:07:25.227344Z","shell.execute_reply":"2025-08-04T18:07:27.440243Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"W0000 00:00:1754330845.280010   33627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/input/karsl-502/01/01/train:   0%|          | 0/499 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9662f5b5fce1459c875fe932bcde8288"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/42 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e5c7ef69e143cf80461b487ed52d10"}},"metadata":{}},{"name":"stderr","text":"W0000 00:00:1754330845.308309   33619 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330845.322602   33626 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330845.361496   33620 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330845.403475   33622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330845.457654   33622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.211736   33629 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.254917   33629 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.262952   33621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.302269   33623 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.304484   33618 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.365824   33623 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.853743   33627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.869343   33621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.877025   33626 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.894236   33621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330846.969315   33625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1754330847.030221   33625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3951843142.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mstore_keypoint_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkps_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mextract_keypoints_from_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKPS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3951843142.py\u001b[0m in \u001b[0;36mextract_keypoints_from_frames\u001b[0;34m(data_dir, kps_dir, signers, splits)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# selected_words = [f'{3:04}'] # [f\"{w:04}\" for w in range(1, 503)][2::999999]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mselected_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{w:04}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mstore_keypoint_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkps_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mextract_keypoints_from_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKPS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3597878032.py\u001b[0m in \u001b[0;36mstore_keypoint_arrays\u001b[0;34m(data_dir, out_dir, signer, split, selected_words)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# with mp_holistic(refine_face_landmarks=True) as holistic:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 video_kps.append(\n\u001b[1;32m     97\u001b[0m                     \u001b[0;31m# extract_frame_keypoints(mediapipe_detection(frame, holistic))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":224},{"cell_type":"code","source":"def load_keypoints(kps_dir, f_avg, split, words=None, signers=None):\n    def pad_seq_(x, padding_amount):\n        x = np.concatenate((x, np.repeat(x[-1], padding_amount, axis=0)), axis=0)\n\n    signers = signers or [\"01\", \"02\", \"03\"]\n    words = words or tuple((f\"{v:04}\" for v in range(1, 503)))\n\n    kps_data_path = os_join(kps_dir, \"all_kps\")\n    sequences = []\n    for word in tqdm(words[:1]):\n        for signer in signers:\n            word_dir = os_join(kps_data_path, f\"{signer}-{split}\", word)\n            sequences.append(\n                [np.load(os_join(word_dir, video)) for video in os.listdir(word_dir)]\n            )\n    return sequences\n    X = np.array(sequences)\n    y = np.array([label_map[word] for word in words])\n    y = OneHotEncoder(sparse=False).fit_transform(y.reshape(-1, 1))\n\n    return X, y\n\n# X, y = load_keypoints(KPS_DIR, SEQ_LEN, \"train\")\nseq = load_keypoints(KPS_DIR, SEQ_LEN, \"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:51:59.274331Z","iopub.execute_input":"2025-08-04T15:51:59.274870Z","iopub.status.idle":"2025-08-04T15:51:59.291769Z","shell.execute_reply.started":"2025-08-04T15:51:59.274847Z","shell.execute_reply":"2025-08-04T15:51:59.290936Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe3cb4a83054a1ca36f928fd6ca94a0"}},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"len(seq), len(seq[0]), len(seq[1]), len(seq[2]), seq[0][0].shape, seq[1][0].shape, seq[2][0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T15:53:15.062618Z","iopub.execute_input":"2025-08-04T15:53:15.062951Z","iopub.status.idle":"2025-08-04T15:53:15.068875Z","shell.execute_reply.started":"2025-08-04T15:53:15.062927Z","shell.execute_reply":"2025-08-04T15:53:15.068173Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(3, 1, 1, 1, (19, 184, 3), (23, 184, 3), (25, 184, 3))"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"np.concatenate(seq, axis=1).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T17:58:05.739204Z","iopub.execute_input":"2025-08-04T17:58:05.739682Z","iopub.status.idle":"2025-08-04T17:58:05.745124Z","shell.execute_reply.started":"2025-08-04T17:58:05.739657Z","shell.execute_reply":"2025-08-04T17:58:05.744476Z"}},"outputs":[{"execution_count":203,"output_type":"execute_result","data":{"text/plain":"(1, 67, 184, 3)"},"metadata":{}}],"execution_count":203},{"cell_type":"code","source":"!tar -cf all-kps /kaggle/working/karsl-kps/all_kps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T16:57:04.672695Z","iopub.execute_input":"2025-08-04T16:57:04.673100Z","iopub.status.idle":"2025-08-04T16:57:04.888870Z","shell.execute_reply.started":"2025-08-04T16:57:04.673073Z","shell.execute_reply":"2025-08-04T16:57:04.888122Z"}},"outputs":[{"name":"stdout","text":"tar: Removing leading `/' from member names\n","output_type":"stream"}],"execution_count":167},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T14:12:11.455713Z","iopub.execute_input":"2025-08-03T14:12:11.456135Z","iopub.status.idle":"2025-08-03T14:12:12.943087Z","shell.execute_reply.started":"2025-08-03T14:12:11.456107Z","shell.execute_reply":"2025-08-03T14:12:12.942224Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}